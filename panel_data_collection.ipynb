{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGM Economic Experts Panel Data Collection\n",
    "## Oliver Gladfelter\n",
    "### Jan 6th, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Open http://www.igmchicago.org/igm-economic-experts-panel and save web page as an HTML file\n",
    "## 2) Access HTML file and scrape each month's publish date, title, and url. Save csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"IGM Economic Experts Panel _ IGM Forum.html\", encoding='utf8') as f:\n",
    "    \n",
    "    contents = f.read()\n",
    "\n",
    "    bs = BeautifulSoup(contents, 'lxml')\n",
    "    \n",
    "divs = (bs.findAll('div', {\"class\":[\"poll-listing poll-results\", \"post poll-results\"]}))\n",
    "\n",
    "dateTime = []\n",
    "url = []\n",
    "title = []\n",
    "\n",
    "for div in divs:\n",
    "    dateTime.append(div.find('h6').text)\n",
    "    url.append(div.find('a')['href'])\n",
    "    title.append(div.find('h2').text)\n",
    "    \n",
    "df = pd.DataFrame({'date':dateTime, 'title': title, 'url':url})\n",
    "\n",
    "df.to_csv(\"output-data\\\\IGMPanelLinks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) All survey questions' web pages also need to be saved as HTML files. We stored them in the 'survey-html-files' folder. \n",
    "## 4) Open all files in the folder, scrape the answers data, export csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'survey-html-files'\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    filenames.append(filename)\n",
    "    \n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] # add finished dataframes to this list\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "\n",
    "    with open(\"survey-html-files\\\\\" + filename, encoding='utf8') as f:\n",
    "\n",
    "        contents = f.read()\n",
    "\n",
    "        bs = BeautifulSoup(contents, 'lxml')\n",
    "\n",
    "    questionList = []\n",
    "    dateTimeList = []\n",
    "    nameList = []\n",
    "    voteList = []\n",
    "    confidenceList = []\n",
    "\n",
    "    # scrape the date\n",
    "    date = bs.findAll('h6')[0].text\n",
    "\n",
    "    # scrape the questions\n",
    "    questions = bs.findAll('h3', {'class':'surveyQuestion'})\n",
    "\n",
    "    # append each question to list, after removing new lines and leading space\n",
    "    questionText = []\n",
    "    for question in questions:\n",
    "        questionText.append(re.sub(\"\\n\", \"\", question.text).strip(\" \"))\n",
    "\n",
    "    # determine how many tables there are (should be equal to number of questions)\n",
    "    numTables = len(bs.findAll('table'))\n",
    "\n",
    "    # for each table...\n",
    "    for table in range(0,numTables):\n",
    "\n",
    "        # find all the rows containing data    \n",
    "        tableRows = bs.findAll('table')[table].findAll('tr', {\"class\":\"parent-row\"})\n",
    "\n",
    "        # for each row...\n",
    "        for row in tableRows:\n",
    "            columns = row.findAll('td') # select all columns\n",
    "            nameList.append(columns[0].text.strip(\"\\n\").strip(\"\\t\")) # pull name\n",
    "            voteList.append(columns[2].text.strip(\"\\n\").strip(\"\\t\")) # pull vote\n",
    "            confidenceList.append(columns[3].text.strip(\"\\n\").strip(\"\\t\")) # pull vote\n",
    "\n",
    "            questionList.append(questionText[table]) # add corresponding question to list\n",
    "            dateTimeList.append(date)\n",
    "\n",
    "    # convert lists to dataframe and append to data list\n",
    "    data.append(pd.DataFrame({'question':questionList, 'date':dateTimeList, 'name':nameList, 'vote':voteList, 'confidence':confidenceList}))\n",
    "\n",
    "# convert lists of dataframes into one dataframe\n",
    "data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"output-data\\\\answers.csv\", index=False)\n",
    "\n",
    "# saving data in pivot form\n",
    "dataPivot = data.drop_duplicates(['question', 'name']).pivot(index='name', columns='question', values='vote').reset_index()\n",
    "dataPivot.to_csv(\"output-data\\\\answersAsColumns.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
